{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mucosmo/pythonTutorial/blob/main/Wav2Lip_HQ_pretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZjndS62ERVc"
      },
      "source": [
        "# Wav2Lip-HQ finetuning\n",
        "\n",
        "**This notebook doesn't cover inference. For running Wav2Lip-HQ, please refer to [this notebook](https://colab.research.google.com/drive/1bwgV-31JLNFTKCVDnJtTbP4brOUV1xaL?usp=sharing).**\n",
        "\n",
        "Here we describe how to finetune Wav2Lip-HQ super resolution model on your own videos which may sometimes be necessary for obtaining high-quality result. You can find more details in [our GitHub repository](https://github.com/Markfryazino/wav2lip-hq)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9bO7Gb5G0mr"
      },
      "source": [
        "## First of all, clone the repository and load all required models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khrOZHyPfKTR"
      },
      "source": [
        "!git clone https://github.com/Markfryazino/wav2lip-hq.git\n",
        "%cd wav2lip-hq\n",
        "!pip3 install gdown\n",
        "!pip3 install -r requirements.txt\n",
        "\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7DyNrSoG5FH",
        "outputId": "9cb5bf54-f5a1-4a98-9ee5-caf1cf6e32d7"
      },
      "source": [
        "import gdown\n",
        "\n",
        "urls = {\n",
        "    \"wav2lip_gan.pth\": \"10Iu05Modfti3pDbxCFPnofmfVlbkvrCm\",\n",
        "    \"face_segmentation.pth\": \"154JgKpzCPW82qINcVieuPH3fZ2e0P812\",\n",
        "    \"esrgan_yunying.pth\": \"1aB-jqBikcZPJnFrJXWUEpvF2RFCuerSe\",\n",
        "    \"pretrained.state\": \"1_MGeOLdARWHylC1PCU2p5_FQztD4Bo7B\"\n",
        "}\n",
        "\n",
        "for name, id in urls.items():\n",
        "    url = f\"https://drive.google.com/uc?id={id}\"\n",
        "    output = f\"checkpoints/{name}\"\n",
        "    gdown.download(url, output, quiet=False)\n",
        "    print(f\"Loaded {name}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10Iu05Modfti3pDbxCFPnofmfVlbkvrCm\n",
            "To: /content/wav2lip-hq/checkpoints/wav2lip_gan.pth\n",
            "436MB [00:04, 104MB/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded wav2lip_gan.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=154JgKpzCPW82qINcVieuPH3fZ2e0P812\n",
            "To: /content/wav2lip-hq/checkpoints/face_segmentation.pth\n",
            "53.3MB [00:00, 249MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded face_segmentation.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aB-jqBikcZPJnFrJXWUEpvF2RFCuerSe\n",
            "To: /content/wav2lip-hq/checkpoints/esrgan_yunying.pth\n",
            "67.0MB [00:00, 93.1MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded esrgan_yunying.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_MGeOLdARWHylC1PCU2p5_FQztD4Bo7B\n",
            "To: /content/wav2lip-hq/checkpoints/pretrained.state\n",
            "311MB [00:04, 72.1MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded pretrained.state\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmEOc-H9HAcO"
      },
      "source": [
        "## Now upload target video.\n",
        "\n",
        "You can just upload via Google Colab interface or load from Google Drive, which can be more quick."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iMJaiwvG_rT",
        "outputId": "80e4cdb1-9bda-4d42-aa8c-5387562e69c3"
      },
      "source": [
        "# If you load files from Drive, run this cell\n",
        "\n",
        "# Paste the filename and Google Drive ID of your video below.\n",
        "urls = {\n",
        "    \"yunying_30s.mp4\": \"1dggydm07RHrxiFUIH_51RXmkMcD_bMPE\",\n",
        "}\n",
        "\n",
        "for name, id in urls.items():\n",
        "    url = f\"https://drive.google.com/uc?id={id}\"\n",
        "    output = f\"videos/{name}\"\n",
        "    gdown.download(url, output, quiet=False)\n",
        "    print(f\"Loaded {name}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dggydm07RHrxiFUIH_51RXmkMcD_bMPE\n",
            "To: /content/wav2lip-hq/videos/yunying_30s.mp4\n",
            "12.0MB [00:00, 70.5MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded yunying_30s.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUnZiWJUHTeE"
      },
      "source": [
        "## Run Wav2Lip with frame saving.\n",
        "\n",
        "Please, replace `--face` and `--audio` arguments with the same path to your target video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2dHPYwtHSSA",
        "outputId": "fdead403-875b-44a1-9d60-c8813d00ecfd"
      },
      "source": [
        "!mkdir data/gt\n",
        "!mkdir data/lq\n",
        "!mkdir data/hq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wtssIfXJxHS"
      },
      "source": [
        "!python3 inference.py \\\n",
        "        --checkpoint_path \"checkpoints/wav2lip_gan.pth\" \\\n",
        "        --segmentation_path \"checkpoints/face_segmentation.pth\" \\\n",
        "        --sr_path \"checkpoints/esrgan_yunying.pth\" \\\n",
        "        --face \"videos/yunying_30s.mp4\" \\\n",
        "        --audio \"videos/yunying_30s.mp4\" \\\n",
        "        --save_frames \\\n",
        "        --gt_path \"data/gt\" \\\n",
        "        --pred_path \"data/lq\" \\\n",
        "        --no_sr \\\n",
        "        --no_segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaBsX6uGNxwx"
      },
      "source": [
        "The snippet below is required to resize ground truth images to 384 $\\times$ 384 resolution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNfh2cP5NaFo"
      },
      "source": [
        "import os\n",
        "\n",
        "paths = os.listdir(\"data/gt\")\n",
        "\n",
        "for img_path in tqdm(paths):\n",
        "    img = cv2.imread(\"data/gt/\" + img_path)\n",
        "    img = cv2.resize(img, (384, 384))\n",
        "    cv2.imwrite(\"data/hq/\" + img_path, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZeY5rJTMaCM"
      },
      "source": [
        "## Finetune ESRGAN\n",
        "\n",
        "In general, the longer you train the model, the better. However, a couple of hours is usually enough, so feel free to stop execution if you want to.\n",
        "\n",
        "After executing this cell the pretrained generator will be stored as `experiments/001_ESRGAN_x4_f64b23_custom16k_500k_B16G1_wandb/models/net_g_latest.pth`. Download it and pass as the `--sr_path` argument to `inference.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2SNxHt0KYSK"
      },
      "source": [
        "!PYTHONPATH=\"./:${PYTHONPATH}\"\n",
        "!CUDA_VISIBLE_DEVICES=0\n",
        "!python3 basicsr/train.py -opt train_basicsr.yml"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}